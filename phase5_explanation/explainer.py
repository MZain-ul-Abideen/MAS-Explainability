"""
Phase 5: LLM-Based Explainer (HuggingFace Version)
Generates natural language explanations from structured evidence.
"""

from typing import Optional
from pathlib import Path
import json
import os
from huggingface_hub import InferenceClient
from pydantic import BaseModel, Field
from dotenv import load_dotenv

# Load environment variables
load_dotenv()


class Explanation(BaseModel):
    """Natural language explanation generated by LLM."""
    query: str
    answer: str
    evidence_used: dict = Field(default_factory=dict)
    token_usage: Optional[dict] = None


class Explainer:
    """
    Generates natural language explanations using HuggingFace LLM.
    
    Uses RAG approach: retrieval is done in Phase 4, LLM only reasons over
    retrieved facts to generate human-readable explanations.
    """
    
    def __init__(self, api_token: Optional[str] = None, model: str = None):
        """
        Initialize explainer with HuggingFace API.
        
        Args:
            api_token: HuggingFace API token (or set HF_API_TOKEN env var)
            model: Model to use (default: meta-llama/Llama-3.3-70B-Instruct)
        """
        self.api_token = api_token or os.getenv("HF_API_TOKEN")
        
        if not self.api_token:
            raise ValueError(
                "HuggingFace API token required. Set HF_API_TOKEN environment variable "
                "or pass api_token parameter."
            )
        
        # Use a capable open-source model
        self.model = model or "meta-llama/Llama-3.3-70B-Instruct"
        
        # Initialize HuggingFace client
        self.client = InferenceClient(token=self.api_token)
    
    def _build_system_prompt(self) -> str:
        """Build system prompt for the LLM."""
        return """You are an explainability assistant for Multi-Agent Systems (MAS).

Your role is to explain what happened in a MAS based ONLY on the evidence provided to you. 

CRITICAL RULES:
1. Base ALL answers ONLY on the provided evidence (norms, logs, compliance results, agent profiles)
2. NEVER invent or assume information not present in the evidence
3. If evidence is insufficient, say so explicitly
4. Be concise but complete
5. Use natural language suitable for non-experts
6. Reference specific evidence when making claims (e.g., "According to norm n1...", "Log entry 42 shows...")
7. Distinguish between facts (from evidence) and interpretations

When explaining:
- Agent behavior: Use log entries and agent profiles
- Norms: Reference the norm specifications
- Compliance: Use compliance results and cite specific evidence
- Timeline: Use temporal ordering from logs
- System overview: Synthesize from all available evidence

Remember: You are explaining what the system DID (past tense), not what it could do or should do."""
    
    def _format_evidence(self, evidence_packet: dict) -> str:
        """Format evidence packet into a readable context for the LLM."""
        sections = []
        
        # System Overview
        if evidence_packet.get('system_overview'):
            overview = evidence_packet['system_overview']
            sections.append(f"""SYSTEM OVERVIEW:
- Total Agents: {overview.get('total_agents', 0)}
- Total Norms: {overview.get('total_norms', 0)}
- Total Missions: {overview.get('total_missions', 0)}
- Total Events: {overview.get('total_events', 0)}
- Compliance Summary: {json.dumps(overview.get('compliance_summary', {}), indent=2)}
""")
        
        # Relevant Agents
        if evidence_packet.get('relevant_agents'):
            sections.append("RELEVANT AGENTS:")
            for agent in evidence_packet['relevant_agents'][:10]:  # Limit to 10
                sections.append(f"""
Agent: {agent['agent_id']}
- Role: {agent.get('inferred_role') or 'unknown'}
- Total Actions: {agent.get('total_actions', 0)}
- Unique Actions: {agent.get('unique_actions', 0)}
- Top Actions: {', '.join(list(agent.get('action_summary', {}).keys())[:5])}
- Applicable Norms: {', '.join(agent.get('applicable_norms', []))}
- Compliance: {json.dumps(agent.get('compliance_status', {}), indent=2)}
""")
        
        # Relevant Norms
        if evidence_packet.get('relevant_norms'):
            sections.append("\nRELEVANT NORMS:")
            for norm in evidence_packet['relevant_norms']:
                sections.append(f"""
Norm {norm['norm_id']}:
- Type: {norm['norm_type']}
- Role: {norm.get('role') or 'N/A'}
- Mission: {norm.get('mission') or 'N/A'}
- Condition: {norm.get('condition') or 'N/A'}
- Action: {norm.get('action') or 'N/A'}
""")
        
        # Relevant Missions
        if evidence_packet.get('relevant_missions'):
            sections.append("\nRELEVANT MISSIONS:")
            for mission in evidence_packet['relevant_missions']:
                sections.append(f"""
Mission: {mission['mission_name']}
- Required Roles: {', '.join(mission.get('required_roles', []))}
- Associated Norms: {', '.join(mission.get('associated_norms', []))}
- Agents Assigned: {', '.join(mission.get('agents_assigned', []))}
- Fulfillment Status: {json.dumps(mission.get('fulfillment_status', {}), indent=2)}
""")
        
        # Relevant Compliance Results
        if evidence_packet.get('relevant_compliance'):
            sections.append("\nCOMPLIANCE RESULTS:")
            for comp in evidence_packet['relevant_compliance'][:20]:  # Limit to 20
                sections.append(f"""
Agent: {comp['agent_id']} | Norm: {comp['norm_id']} | Status: {comp['status']}
- Reasoning: {comp.get('reasoning', 'N/A')}
- Evidence Count: {len(comp.get('evidence', []))}
""")
                
                # Include evidence entries
                if comp.get('evidence'):
                    sections.append("  Supporting Evidence:")
                    for ev in comp['evidence'][:3]:  # Show up to 3 evidence items
                        sections.append(f"    - Entry {ev.get('entry_id')}: {ev.get('action', 'N/A')}")
        
        # Relevant Log Entries (sample)
        if evidence_packet.get('relevant_log_entries'):
            log_count = len(evidence_packet['relevant_log_entries'])
            sections.append(f"\nRELEVANT LOG ENTRIES ({log_count} total, showing sample):")
            
            # Show first 20 and last 5
            sample_logs = evidence_packet['relevant_log_entries'][:20]
            if log_count > 25:
                sample_logs.extend(evidence_packet['relevant_log_entries'][-5:])
            
            for entry in sample_logs:
                temporal = entry.get('sequence_number') or entry.get('timestamp')
                sections.append(f"""
[{temporal}] {entry['agent_id']}: {entry['action']}
""")
        
        # Relevant Interactions
        if evidence_packet.get('relevant_interactions'):
            sections.append("\nRELEVANT INTERACTIONS:")
            for interaction in evidence_packet['relevant_interactions']:
                sections.append(f"""
{interaction['source_agent']} -> {interaction.get('target_agent', 'system')}
- Type: {interaction['interaction_type']}
- Frequency: {interaction['frequency']}
""")
        
        return "\n".join(sections)
    
    def explain(self, query: str, evidence_packet: dict) -> Explanation:
        """
        Generate natural language explanation for a query.
        
        Args:
            query: User's question
            evidence_packet: Retrieved evidence from Phase 4
            
        Returns:
            Explanation object with natural language answer
        """
        # Format evidence
        evidence_text = self._format_evidence(evidence_packet)
        
        # Build messages for chat completion
        messages = [
            {
                "role": "system",
                "content": self._build_system_prompt()
            },
            {
                "role": "user",
                "content": f"""Query: {query}

Evidence:
{evidence_text}

Based ONLY on the evidence above, provide a clear, concise answer to the query.
If the evidence is insufficient to fully answer the query, state what is known and what is missing."""
            }
        ]
        
        # Call HuggingFace API
        try:
            completion = self.client.chat_completion(
                messages=messages,
                model=self.model,
                max_tokens=2000,
                temperature=0.3  # Lower temperature for more factual responses
            )
            
            answer = completion.choices[0].message.content
            
            # Track token usage (if available)
            token_usage = {
                'model': self.model,
                'total_tokens': completion.usage.total_tokens if hasattr(completion, 'usage') else None,
                'prompt_tokens': completion.usage.prompt_tokens if hasattr(completion, 'usage') else None,
                'completion_tokens': completion.usage.completion_tokens if hasattr(completion, 'usage') else None
            }
            
        except Exception as e:
            answer = f"Error generating explanation: {str(e)}\n\nPlease check:\n1. HF_API_TOKEN is set correctly\n2. Model '{self.model}' is accessible\n3. You have API credits"
            token_usage = {'error': str(e)}
        
        # Build evidence summary
        evidence_used = {
            'agents': len(evidence_packet.get('relevant_agents', [])),
            'norms': len(evidence_packet.get('relevant_norms', [])),
            'missions': len(evidence_packet.get('relevant_missions', [])),
            'log_entries': len(evidence_packet.get('relevant_log_entries', [])),
            'compliance_results': len(evidence_packet.get('relevant_compliance', [])),
            'interactions': len(evidence_packet.get('relevant_interactions', []))
        }
        
        return Explanation(
            query=query,
            answer=answer,
            evidence_used=evidence_used,
            token_usage=token_usage
        )


def generate_explanation(
    query: str,
    evidence_packet: dict,
    api_token: Optional[str] = None,
    model: Optional[str] = None
) -> Explanation:
    """
    Convenience function to generate explanation.
    
    Args:
        query: User's question
        evidence_packet: Retrieved evidence
        api_token: HuggingFace API token (optional)
        model: Model to use (optional)
        
    Returns:
        Explanation object
    """
    explainer = Explainer(api_token=api_token, model=model)
    return explainer.explain(query, evidence_packet)